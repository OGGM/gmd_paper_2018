{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/OGGM/oggm/master/docs/_static/logo.png\" width=\"40%\"  align=\"left\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import salem\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ref Table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the RGI\n",
    "import geopandas as gpd\n",
    "import glob, os\n",
    "import oggm\n",
    "from oggm.utils import get_rgi_dir\n",
    "frgi = '/home/mowglie/Documents/OGGM_Experiments/rgi60_allglaciers.csv'\n",
    "rgi_dir = get_rgi_dir(version='6')\n",
    "if not os.path.exists(frgi):\n",
    "    # one time action only\n",
    "    fs = list(sorted(glob.glob(rgi_dir + \"/*/*_rgi60_*.shp\")))[2:]\n",
    "    out = []\n",
    "    for f in fs:\n",
    "        sh = gpd.read_file(f).set_index('RGIId')\n",
    "        del sh['geometry']\n",
    "        out.append(sh)\n",
    "    mdf = pd.concat(out)\n",
    "    mdf.to_csv(frgi)\n",
    "mdf = pd.read_csv(frgi, index_col=0, converters={'Form': str, 'TermType': str, 'RGIFlag':str, 'BgnDate':str, \n",
    "                                                 'EndDate':str, 'O1Region': str, 'O2Region':str, 'Name':str})\n",
    "mdf['RGI_REG'] = [rid.split('-')[1].split('.')[0] for rid in mdf.index]\n",
    "# Read glacier attrs\n",
    "gtkeys = {'0': 'Glacier',\n",
    "          '1': 'Ice cap',\n",
    "          '2': 'Perennial snowfield',\n",
    "          '3': 'Seasonal snowfield',\n",
    "          '9': 'Not assigned',\n",
    "          }\n",
    "ttkeys = {'0': 'Land-terminating',\n",
    "          '1': 'Marine-terminating',\n",
    "          '2': 'Lake-terminating',\n",
    "          '3': 'Dry calving',\n",
    "          '4': 'Regenerated',\n",
    "          '5': 'Shelf-terminating',\n",
    "          '9': 'Not assigned',\n",
    "          }\n",
    "mdf['GlacierType'] = [gtkeys[g] for g in mdf.Form]\n",
    "mdf['TerminusType'] = [ttkeys[g] for g in mdf.TermType]\n",
    "mdf['IsTidewater'] = [ttype in ['Marine-terminating', 'Lake-terminating'] for ttype in mdf.TerminusType]\n",
    "mdf['RGIId'] = mdf.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"GlacierType\", data=mdf);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"RGI_REG\", data=mdf);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 largest\n",
    "mdf.sort_values(by='Area').iloc[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf = mdf.loc[mdf.RGI_REG != '19']\n",
    "print(len(mdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = '/home/mowglie/disk/OGGM_Output/run_output_summary/'\n",
    "rgi_regs = ['rgi_reg_{:02}'.format(p) for p in np.arange(1, 19)]\n",
    "df = pd.DataFrame()\n",
    "for r in rgi_regs:\n",
    "    ldir = os.path.join(dd, r, 'log/*.ERROR')\n",
    "    paths = glob.glob(ldir)\n",
    "    for p in sorted(paths):\n",
    "        rid = os.path.basename(p).replace('.ERROR', '')\n",
    "        df.loc[rid, 'RGI_REG'] = os.path.basename(p).split('-')[1].split('.')[0]\n",
    "        with open(p, 'r') as f:\n",
    "            first_line = f.readline().replace('\\n', '')\n",
    "        df.loc[rid, 'TASK'] = first_line.split(';')[1].strip()\n",
    "        df.loc[rid, 'TYPE'] = first_line.split(';')[2].strip()\n",
    "        df.loc[rid, 'MESSAGE'] = ' '.join(first_line.split(';')[3:]).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(df.index.get_duplicates()) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add mine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inv\n",
    "dd = '/home/mowglie/disk/OGGM_Output/run_output_summary'\n",
    "rgi_regs = ['rgi_reg_{:02}'.format(p) for p in np.arange(1, 19)]\n",
    "dfi = []\n",
    "for r in rgi_regs:\n",
    "    p = os.path.join(dd, r, 'glacier_characteristics.csv')\n",
    "    _df = pd.read_csv(p, index_col=0, low_memory=False)\n",
    "    _df['RGI_REG'] = r[-2:]\n",
    "    dfi.append(_df)\n",
    "dfi = pd.concat(dfi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfi = dfi.loc[~dfi.index.isin(df.index)]\n",
    "assert np.all(~dfi.inv_thickness_m.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfi_dem_err = dfi.loc[(dfi.flowline_max_elev - dfi.flowline_min_elev) <= 1].copy()\n",
    "dfi_dem_err = dfi_dem_err[['RGI_REG']]\n",
    "dfi_dem_err['TASK'] = 'glacier_masks'\n",
    "dfi_dem_err['TYPE'] = 'RuntimeError'\n",
    "dfi_dem_err['MESSAGE'] = 'DEM in glacier too flat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfi = dfi.loc[~dfi.index.isin(dfi_dem_err.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfi_pcp_err = dfi.loc[dfi.tstar_avg_prcpsol_max_elev <= 10].copy()\n",
    "dfi_pcp_err = dfi_pcp_err[['RGI_REG']]\n",
    "dfi_pcp_err['TASK'] = 'local_mustar'\n",
    "dfi_pcp_err['TYPE'] = 'RuntimeError'\n",
    "dfi_pcp_err['MESSAGE'] = 'Prcp < 10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfi = dfi.loc[~dfi.index.isin(dfi_pcp_err.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfi_mu_err = dfi.loc[dfi.mu_star < 1].copy()\n",
    "dfi_mu_err = dfi_mu_err[['RGI_REG']]\n",
    "dfi_mu_err['TASK'] = 'local_mustar'\n",
    "dfi_mu_err['TYPE'] = 'RuntimeError'\n",
    "dfi_mu_err['MESSAGE'] = 'mu < 1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, dfi_dem_err, dfi_pcp_err, dfi_mu_err])\n",
    "assert len(df.index.get_duplicates()) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerics\n",
    "# Inv\n",
    "dd = '/home/mowglie/disk/OGGM_Output/run_output_summary'\n",
    "dfn = []\n",
    "for r in rgi_regs:\n",
    "    p = os.path.join(dd, r, 'task_log.csv')\n",
    "    _df = pd.read_csv(p, index_col=0)\n",
    "    _df['RGI_REG'] = r[-2:]\n",
    "    dfn.append(_df)\n",
    "dfn = pd.concat(dfn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We do it for all relevant tasks\n",
    "tasks = ['random_glacier_evolution_rdn_tstar' , 'random_glacier_evolution_rdn_2000',\n",
    "         'random_glacier_evolution_rdn_2000_tbias_p05', 'random_glacier_evolution_rdn_2000_tbias_m05']\n",
    "for t in tasks:\n",
    "    dfn = dfn.loc[~dfn.index.isin(df.index)]\n",
    "    dfn_err = dfn.loc[dfn[t] != 'SUCCESS'].copy()\n",
    "    dfn_err = dfn_err[['RGI_REG', t]]\n",
    "    dfn_err.columns = ['RGI_REG', 'MESSAGE']\n",
    "    dfn_err['TASK'] = 'random_glacier_evolution'\n",
    "    dfn_err['TYPE'] = 'RuntimeError'\n",
    "    dfn_err = dfn_err[df.columns]\n",
    "    df = pd.concat([df, dfn_err])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_index()\n",
    "assert len(df.index.get_duplicates()) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse Errors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['AREA'] = mdf.loc[df.index].Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(y=\"RGI_REG\", data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(y=\"TASK\", data=df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.AREA.sum() / mdf.Area.sum() * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = df.groupby('RGI_REG').sum()\n",
    "summary.columns = ['AREA_ERR']\n",
    "summary['N_ERR'] = df.groupby('RGI_REG').count()['TASK']\n",
    "summary['N_GLACIERS'] = mdf.groupby('RGI_REG').count()['GLIMSId']\n",
    "summary['TOTAL_AREA'] = mdf.groupby('RGI_REG').sum()['Area']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from oggm.utils import parse_rgi_meta\n",
    "reg_names, subreg_names = parse_rgi_meta(version='6')\n",
    "summary['REG_NAME'] = [reg_names.loc[int(k)].values[0] for k in summary.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = summary[['REG_NAME', 'N_GLACIERS', 'TOTAL_AREA', 'N_ERR', 'AREA_ERR']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfpre = df.loc[df.TASK.isin(['local_mustar'])]\n",
    "summary['N_ERR_CLIMATE'] = dfpre.groupby('RGI_REG').count()['TASK']\n",
    "summary['AREA_ERR_CLIMATE'] = dfpre.groupby('RGI_REG').sum()['AREA']\n",
    "\n",
    "dfpre = df.loc[df.TASK.isin(['random_glacier_evolution'])]\n",
    "summary['N_ERR_DYNAMS'] = dfpre.groupby('RGI_REG').count()['TASK']\n",
    "summary['AREA_ERR_DYNAMS'] = dfpre.groupby('RGI_REG').sum()['AREA']\n",
    "\n",
    "dfpre = df.loc[~df.TASK.isin(['random_glacier_evolution', 'local_mustar'])]\n",
    "summary['N_ERR_OTHERS'] = dfpre.groupby('RGI_REG').count()['TASK']\n",
    "summary['AREA_ERR_OTHERS'] = dfpre.groupby('RGI_REG').sum()['AREA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = summary.sum()\n",
    "tmp.name = 'TOTAL'\n",
    "summary = summary.append(tmp)\n",
    "summary['PERC_ERR_AREA_TOTAL'] = summary['AREA_ERR'] / summary['TOTAL_AREA'] * 100\n",
    "summary['PERC_ERR_AREA_CLIMATE'] = summary['AREA_ERR_CLIMATE'] / summary['TOTAL_AREA'] * 100\n",
    "summary['PERC_ERR_AREA_DYNAMS'] = summary['AREA_ERR_DYNAMS'] / summary['TOTAL_AREA'] * 100\n",
    "summary['PERC_ERR_AREA_OTHERS'] = summary['AREA_ERR_OTHERS'] / summary['TOTAL_AREA'] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.loc['TOTAL', 'REG_NAME'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = summary.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_latex = pd.DataFrame(index=[i + ': ' + n for i, n in zip(summary.index, summary.REG_NAME)])\n",
    "for_latex['N'] = summary.N_GLACIERS.values \n",
    "for_latex['Area (km2)'] = ['{:.0f}'.format(n) for n in summary.TOTAL_AREA.values] \n",
    "for_latex['Climate'] = ['{} ({:.1f}%)'.format(int(n), p) for n, p in \n",
    "                                zip(summary.N_ERR_CLIMATE, summary.PERC_ERR_AREA_CLIMATE)]\n",
    "for_latex['Dynamics'] = ['{} ({:.1f}%)'.format(int(n), p) for n, p in \n",
    "                                zip(summary.N_ERR_DYNAMS, summary.PERC_ERR_AREA_DYNAMS)]\n",
    "for_latex['Others'] = ['{} ({:.1f}%)'.format(int(n), p) for n, p in \n",
    "                                zip(summary.N_ERR_OTHERS, summary.PERC_ERR_AREA_OTHERS)]\n",
    "for_latex['All'] = ['{} ({:.1f}%)'.format(int(n), p) for n, p in \n",
    "                                zip(summary.N_ERR, summary.PERC_ERR_AREA_TOTAL)]\n",
    "for c in for_latex.columns:\n",
    "    for i, v in for_latex[c].iteritems():\n",
    "        if v == '0 (0.0%)':\n",
    "            for_latex.loc[i, c] = ''\n",
    "for_latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(for_latex.to_latex()\n",
    "      .replace('TOTAL:', 'TOTAL ')\n",
    "      .replace('toprule', 'tophline ')\n",
    "      .replace('midrule', 'middlehline ')\n",
    "      .replace('bottomrule', 'bottomhline ')\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('/home/mowglie/disk/OGGM_Output/list_errors.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per Task analysis for text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = df.loc[df.TASK == 'random_glacier_evolution']\n",
    "dfs.groupby('MESSAGE').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = df.loc[df.TASK == 'local_mustar']\n",
    "dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
