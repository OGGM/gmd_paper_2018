{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/OGGM/oggm/master/docs/_static/logo.png\" width=\"40%\"  align=\"left\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import salem\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __init__ import DATA_DIR, PLOT_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ref Table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the RGI\n",
    "import geopandas as gpd\n",
    "import glob, os\n",
    "import oggm\n",
    "from oggm.utils import get_rgi_dir\n",
    "frgi = '/home/mowglie/Documents/OGGM_Experiments/rgi60_allglaciers.csv'\n",
    "rgi_dir = get_rgi_dir(version='6')\n",
    "if not os.path.exists(frgi):\n",
    "    # one time action only\n",
    "    fs = list(sorted(glob.glob(rgi_dir + \"/*/*_rgi60_*.shp\")))[2:]\n",
    "    out = []\n",
    "    for f in fs:\n",
    "        sh = gpd.read_file(f).set_index('RGIId')\n",
    "        del sh['geometry']\n",
    "        out.append(sh)\n",
    "    mdf = pd.concat(out)\n",
    "    mdf.to_csv(frgi)\n",
    "mdf = pd.read_csv(frgi, index_col=0, converters={'Form': str, 'TermType': str, 'RGIFlag':str, 'BgnDate':str, \n",
    "                                                 'EndDate':str, 'O1Region': str, 'O2Region':str, 'Name':str})\n",
    "mdf['RGI_REG'] = [rid.split('-')[1].split('.')[0] for rid in mdf.index]\n",
    "# Read glacier attrs\n",
    "gtkeys = {'0': 'Glacier',\n",
    "          '1': 'Ice cap',\n",
    "          '2': 'Perennial snowfield',\n",
    "          '3': 'Seasonal snowfield',\n",
    "          '9': 'Not assigned',\n",
    "          }\n",
    "ttkeys = {'0': 'Land-terminating',\n",
    "          '1': 'Marine-terminating',\n",
    "          '2': 'Lake-terminating',\n",
    "          '3': 'Dry calving',\n",
    "          '4': 'Regenerated',\n",
    "          '5': 'Shelf-terminating',\n",
    "          '9': 'Not assigned',\n",
    "          }\n",
    "mdf['GlacierType'] = [gtkeys[g] for g in mdf.Form]\n",
    "mdf['TerminusType'] = [ttkeys[g] for g in mdf.TermType]\n",
    "mdf['IsTidewater'] = [ttype in ['Marine-terminating', 'Lake-terminating'] for ttype in mdf.TerminusType]\n",
    "mdf['RGIId'] = mdf.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"GlacierType\", data=mdf);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=\"RGI_REG\", data=mdf);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf = mdf.loc[mdf.RGI_REG != '19']\n",
    "print(len(mdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = DATA_DIR + 'standard_prepro'\n",
    "rgi_regs = ['{:02}'.format(p) for p in np.arange(1, 19)]\n",
    "df = []\n",
    "for r in rgi_regs:\n",
    "    p = os.path.join(dd, 'glacier_statistics_{}.csv'.format(r))\n",
    "    _df = pd.read_csv(p, index_col=0, low_memory=False)\n",
    "    df.append(_df)\n",
    "df = pd.concat(df, sort=False).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(df) == len(mdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(y=\"error_task\", data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rid, m in df.loc[~df.error_msg.isnull()].error_msg.iteritems():\n",
    "    m = m.replace(rid, 'glacier')\n",
    "    if 'mu* out of specified bounds' in m:\n",
    "        try:\n",
    "            sig = float(m.split(':')[-1])\n",
    "            m = ':'.join(m.split(':')[:-1])\n",
    "            if sig > 9000:\n",
    "                m += ': +'\n",
    "            else:\n",
    "                m += ': -'\n",
    "        except ValueError:\n",
    "            pass\n",
    "    \n",
    "    task = df.loc[rid, 'error_task']\n",
    "    if task in ['local_t_star', 'mu_star_calibration']:\n",
    "        cat = 'climate'\n",
    "    else:\n",
    "        cat = 'others'\n",
    "    \n",
    "    df.loc[rid, 'error_msg'] = m\n",
    "    df.loc[rid, 'error_cat'] = cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(y=\"error_msg\", data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_err = df.loc[~df.error_msg.isnull()].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add dynamics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = DATA_DIR + '/dyn_exps/rgi_reg_{}/task_log.csv'\n",
    "ddf = []\n",
    "for r in rgi_regs:\n",
    "    p = os.path.join(dd.format(r))\n",
    "    _df = pd.read_csv(p, index_col=0, low_memory=False)\n",
    "    ddf.append(_df)\n",
    "ddf = pd.concat(ddf, sort=False).sort_index()\n",
    "# Take only non-2000 because of bug in script \n",
    "ddf = ddf[['run_random_climate_rdn_tstar', 'run_random_climate_rect_rdn_tstar']]\n",
    "# Add corrected\n",
    "dd = DATA_DIR + '/dyn_exps/rgi_reg_{}/task_log_2000bf.csv'\n",
    "_ddf = []\n",
    "for r in rgi_regs:\n",
    "    p = os.path.join(dd.format(r))\n",
    "    _df = pd.read_csv(p, index_col=0, low_memory=False)\n",
    "    _ddf.append(_df)\n",
    "_ddf = pd.concat(_ddf, sort=False).sort_index()\n",
    "assert len(_ddf) == len(ddf)\n",
    "ddf = pd.concat([ddf, _ddf], axis=1, sort=False)\n",
    "# Add bf\n",
    "dd = DATA_DIR + '/dyn_exps/rgi_reg_{}/task_log_noseed_bf.csv'\n",
    "_ddf = []\n",
    "for r in rgi_regs:\n",
    "    p = os.path.join(dd.format(r))\n",
    "    _df = pd.read_csv(p, index_col=0, low_memory=False)\n",
    "    _ddf.append(_df)\n",
    "_ddf = pd.concat(_ddf, sort=False).sort_index()\n",
    "assert len(_ddf) == len(ddf)\n",
    "ddf['run_random_climate_rdn_tstar'] = _ddf['run_random_climate_rdn_tstar_noseed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.loc[_err] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = ddf.where(ddf != 'SUCCESS', other=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in ddf.columns:\n",
    "    cc = ddf[c].value_counts()\n",
    "    print(c, cc[0] / cc.sum()*100)\n",
    "    print(cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "772 - 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ax = sns.countplot(y=\"run_random_climate_rdn_2000\", data=ddf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(y=\"run_random_climate_rect_rdn_tstar\", data=ddf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = ddf.dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[ddf.index, 'error_msg'] = 'Nums'\n",
    "df.loc[ddf.index, 'error_cat'] = 'dynamics'\n",
    "df.loc[ddf.index, 'error_task'] = 'dynamics'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfe = df.loc[~df.error_task.isnull()][['rgi_region', 'rgi_area_km2']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = dfe.groupby('rgi_region').sum()\n",
    "summary.columns = ['AREA_ERR']\n",
    "if 6 not in summary.index:\n",
    "    summary.loc[6, 'AREA_ERR'] = 0\n",
    "summary = summary.sort_index()\n",
    "summary['N_ERR'] = dfe.groupby('rgi_region').count()['rgi_area_km2']\n",
    "summary['N_GLACIERS'] = df.groupby('rgi_region').count()['rgi_area_km2']\n",
    "summary['TOTAL_AREA'] = df.groupby('rgi_region').sum()['rgi_area_km2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from oggm.utils import parse_rgi_meta\n",
    "reg_names, subreg_names = parse_rgi_meta(version='6')\n",
    "summary['REG_NAME'] = [reg_names.loc[int(k)].values[0] for k in summary.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = summary[['REG_NAME', 'N_GLACIERS', 'TOTAL_AREA', 'N_ERR', 'AREA_ERR']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfpre = df.loc[df.error_cat == 'climate']\n",
    "summary['N_ERR_CLIMATE'] = dfpre.groupby('rgi_region').count()['error_cat']\n",
    "summary['AREA_ERR_CLIMATE'] = dfpre.groupby('rgi_region').sum()['rgi_area_km2']\n",
    "\n",
    "dfpre = df.loc[df.error_cat == 'dynamics']\n",
    "summary['N_ERR_DYNAMS'] = dfpre.groupby('rgi_region').count()['error_cat']\n",
    "summary['AREA_ERR_DYNAMS'] = dfpre.groupby('rgi_region').sum()['rgi_area_km2']\n",
    "\n",
    "dfpre = df.loc[df.error_cat == 'others']\n",
    "summary['N_ERR_OTHERS'] = dfpre.groupby('rgi_region').count()['error_cat']\n",
    "summary['AREA_ERR_OTHERS'] = dfpre.groupby('rgi_region').sum()['rgi_area_km2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.index = ['{:02d}'.format(i) for i in summary.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = summary.sum()\n",
    "tmp.name = 'TOTAL'\n",
    "summary = summary.append(tmp)\n",
    "summary['PERC_ERR_AREA_TOTAL'] = summary['AREA_ERR'] / summary['TOTAL_AREA'] * 100\n",
    "summary['PERC_ERR_AREA_CLIMATE'] = summary['AREA_ERR_CLIMATE'] / summary['TOTAL_AREA'] * 100\n",
    "summary['PERC_ERR_AREA_DYNAMS'] = summary['AREA_ERR_DYNAMS'] / summary['TOTAL_AREA'] * 100\n",
    "summary['PERC_ERR_AREA_OTHERS'] = summary['AREA_ERR_OTHERS'] / summary['TOTAL_AREA'] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.loc['TOTAL', 'REG_NAME'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = summary.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_latex = pd.DataFrame(index=[i + ': ' + n for i, n in zip(summary.index, summary.REG_NAME)])\n",
    "for_latex['N'] = summary.N_GLACIERS.values \n",
    "for_latex['Area (km2)'] = ['{:.0f}'.format(n) for n in summary.TOTAL_AREA.values] \n",
    "for_latex['Climate'] = ['{} ({:.1f}%)'.format(int(n), p) for n, p in \n",
    "                                zip(summary.N_ERR_CLIMATE, summary.PERC_ERR_AREA_CLIMATE)]\n",
    "for_latex['Dynamics'] = ['{} ({:.1f}%)'.format(int(n), p) for n, p in \n",
    "                                zip(summary.N_ERR_DYNAMS, summary.PERC_ERR_AREA_DYNAMS)]\n",
    "for_latex['Others'] = ['{} ({:.1f}%)'.format(int(n), p) for n, p in \n",
    "                                zip(summary.N_ERR_OTHERS, summary.PERC_ERR_AREA_OTHERS)]\n",
    "for_latex['All'] = ['{} ({:.1f}%)'.format(int(n), p) for n, p in \n",
    "                                zip(summary.N_ERR, summary.PERC_ERR_AREA_TOTAL)]\n",
    "for c in for_latex.columns:\n",
    "    for i, v in for_latex[c].iteritems():\n",
    "        if v == '0 (0.0%)':\n",
    "            for_latex.loc[i, c] = ''\n",
    "for_latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(for_latex.to_latex()\n",
    "      .replace('TOTAL:', 'TOTAL ')\n",
    "      .replace('toprule', 'tophline ')\n",
    "      .replace('midrule', 'middlehline ')\n",
    "      .replace('bottomrule', 'bottomhline ')\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edf = df[['rgi_region', 'rgi_subregion', \n",
    "          'cenlon', 'cenlat', 'rgi_area_km2', 'glacier_type', \n",
    "          'terminus_type', 'status', \n",
    "          'error_task', 'error_msg', 'error_cat']].dropna()\n",
    "assert len(edf) == len(dfe)\n",
    "edf.to_csv(DATA_DIR + 'error_summary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
